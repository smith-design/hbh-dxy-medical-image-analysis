"""
å®Œæ•´çš„æ¨¡å‹è¯„ä¼°è„šæœ¬
ç”Ÿæˆæ··æ·†çŸ©é˜µã€ROCæ›²çº¿ã€è¯¦ç»†æ€§èƒ½æŒ‡æ ‡ç­‰
"""

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import pandas as pd
import numpy as np
from pathlib import Path
from tqdm import tqdm
import json
import timm

# å¯¼å…¥å¯è§†åŒ–å‡½æ•°
import sys
sys.path.append(str(Path(__file__).parent))
from visualize_results import (
    plot_confusion_matrix,
    plot_per_class_metrics,
    generate_performance_report,
    DISEASE_CLASSES,
    DISEASE_NAMES
)

class HAM10000Dataset(Dataset):
    """HAM10000 æ•°æ®é›†"""

    def __init__(self, metadata_df, img_dir1, img_dir2, transform=None):
        self.metadata = metadata_df.reset_index(drop=True)
        self.img_dir1 = Path(img_dir1)
        self.img_dir2 = Path(img_dir2)
        self.transform = transform
        self.label_map = {cls: idx for idx, cls in enumerate(DISEASE_CLASSES)}

    def __len__(self):
        return len(self.metadata)

    def __getitem__(self, idx):
        row = self.metadata.iloc[idx]
        img_id = row['image_id']
        label = self.label_map[row['dx']]

        # æŸ¥æ‰¾å›¾åƒ
        img_path1 = self.img_dir1 / f"{img_id}.jpg"
        img_path2 = self.img_dir2 / f"{img_id}.jpg"

        if img_path1.exists():
            image = Image.open(img_path1).convert('RGB')
        elif img_path2.exists():
            image = Image.open(img_path2).convert('RGB')
        else:
            image = Image.new('RGB', (224, 224), color='gray')

        if self.transform:
            image = self.transform(image)

        return image, label

def evaluate_model(model_dir='models/skin_lesion_classifier', dataset_dir='datasets/archive (6)'):
    """å®Œæ•´è¯„ä¼°æ¨¡å‹"""

    model_dir = Path(model_dir)
    dataset_dir = Path(dataset_dir)

    print("="*60)
    print("ğŸ” å¼€å§‹å®Œæ•´æ¨¡å‹è¯„ä¼°")
    print("="*60)

    # åŠ è½½æ¨¡å‹
    checkpoint_path = model_dir / 'best_model.pth'
    if not checkpoint_path.exists():
        print(f"âŒ æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {checkpoint_path}")
        return

    print(f"\nğŸ“¦ åŠ è½½æ¨¡å‹...")
    checkpoint = torch.load(checkpoint_path, map_location='cpu')

    # åˆ›å»ºæ¨¡å‹
    model_name = checkpoint.get('model_name', 'efficientnet_b0')
    model = timm.create_model(model_name, pretrained=False, num_classes=7)
    model.load_state_dict(checkpoint['model_state_dict'])

    # è®¾å¤‡
    if torch.backends.mps.is_available():
        device = torch.device('mps')
    elif torch.cuda.is_available():
        device = torch.device('cuda')
    else:
        device = torch.device('cpu')

    print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {device}")
    model = model.to(device)
    model.eval()

    # æ•°æ®è½¬æ¢
    val_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

    # åŠ è½½æ•°æ®
    print(f"\nğŸ“Š åŠ è½½éªŒè¯æ•°æ®...")
    metadata = pd.read_csv(dataset_dir / "HAM10000_metadata.csv")

    from sklearn.model_selection import train_test_split
    _, val_df = train_test_split(
        metadata,
        test_size=0.2,
        stratify=metadata['dx'],
        random_state=42
    )

    print(f"âœ… éªŒè¯é›†: {len(val_df)} æ ·æœ¬")

    val_dataset = HAM10000Dataset(
        val_df,
        dataset_dir / "HAM10000_images_part_1",
        dataset_dir / "HAM10000_images_part_2",
        transform=val_transform
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=32,
        shuffle=False,
        num_workers=0
    )

    # è¯„ä¼°
    print(f"\nğŸ” å¼€å§‹è¯„ä¼°...")
    all_preds = []
    all_labels = []
    all_probs = []

    with torch.no_grad():
        for images, labels in tqdm(val_loader, desc="Evaluating"):
            images = images.to(device)
            outputs = model(images)
            probs = torch.softmax(outputs, dim=1)

            _, predicted = outputs.max(1)

            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.numpy())
            all_probs.extend(probs.cpu().numpy())

    all_preds = np.array(all_preds)
    all_labels = np.array(all_labels)
    all_probs = np.array(all_probs)

    # è®¡ç®—å‡†ç¡®ç‡
    accuracy = 100. * (all_preds == all_labels).sum() / len(all_labels)
    print(f"\nâœ… éªŒè¯å‡†ç¡®ç‡: {accuracy:.2f}%")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = model_dir / 'visualizations'
    output_dir.mkdir(exist_ok=True)

    # ç”Ÿæˆå¯è§†åŒ–
    print(f"\nğŸ“ˆ ç”Ÿæˆæ··æ·†çŸ©é˜µ...")
    cm = plot_confusion_matrix(all_labels, all_preds, output_dir)

    print(f"\nğŸ“Š ç”Ÿæˆå„ç±»åˆ«æ€§èƒ½æŒ‡æ ‡...")
    report = plot_per_class_metrics(all_labels, all_preds, output_dir)

    # åŠ è½½è®­ç»ƒå†å²
    history_path = model_dir / 'training_history.json'
    with open(history_path, 'r') as f:
        history = json.load(f)

    print(f"\nğŸ“ ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š...")
    generate_performance_report(history, report, cm, output_dir)

    print("\n" + "="*60)
    print("âœ… è¯„ä¼°å®Œæˆï¼")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print("\nç”Ÿæˆçš„æ–‡ä»¶:")
    print("  1. confusion_matrix.png - æ··æ·†çŸ©é˜µ")
    print("  2. per_class_metrics.png - å„ç±»åˆ«æ€§èƒ½æŒ‡æ ‡")
    print("  3. performance_report.md - è¯¦ç»†æ€§èƒ½æŠ¥å‘Š")
    print("="*60)

    return {
        'accuracy': accuracy,
        'predictions': all_preds,
        'labels': all_labels,
        'probabilities': all_probs,
        'report': report
    }

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='è¯„ä¼°æ¨¡å‹æ€§èƒ½')
    parser.add_argument('--model-dir', type=str, default='models/skin_lesion_classifier',
                        help='æ¨¡å‹ç›®å½•')
    parser.add_argument('--dataset-dir', type=str, default='datasets/archive (6)',
                        help='æ•°æ®é›†ç›®å½•')

    args = parser.parse_args()

    results = evaluate_model(args.model_dir, args.dataset_dir)
