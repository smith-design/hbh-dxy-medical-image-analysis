"""
è®­ç»ƒå¯è§†åŒ–è„šæœ¬
ç›‘æ§å’Œå¯è§†åŒ–æ¨¡å‹è®­ç»ƒè¿‡ç¨‹
"""

import json
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import pandas as pd
import numpy as np

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# è®¾ç½®æ ·å¼
sns.set_style("whitegrid")
sns.set_palette("husl")

def load_training_logs(log_dir):
    """åŠ è½½è®­ç»ƒæ—¥å¿—"""

    log_file = Path(log_dir) / "trainer_state.json"

    if not log_file.exists():
        print(f"âŒ æœªæ‰¾åˆ°è®­ç»ƒæ—¥å¿—: {log_file}")
        return None

    with open(log_file, 'r') as f:
        state = json.load(f)

    return state

def plot_loss_curves(state, output_dir):
    """ç»˜åˆ¶æŸå¤±æ›²çº¿"""

    log_history = state.get('log_history', [])

    if not log_history:
        print("âš ï¸  æ²¡æœ‰è®­ç»ƒæ—¥å¿—æ•°æ®")
        return

    # æå–è®­ç»ƒå’ŒéªŒè¯æ•°æ®
    train_data = []
    eval_data = []

    for entry in log_history:
        if 'loss' in entry:
            train_data.append({
                'step': entry.get('step', 0),
                'epoch': entry.get('epoch', 0),
         'loss': entry['loss']
        })
        if 'eval_loss' in entry:
            eval_data.append({
                'step': entry.get('step', 0),
                'epoch': entry.get('epoch', 0),
                'eval_loss': entry['eval_loss']
            })

    # åˆ›å»ºå›¾è¡¨
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('æ¨¡å‹è®­ç»ƒå¯è§†åŒ–åˆ†æ', fontsize=16, fontweight='bold')

    # 1. è®­ç»ƒæŸå¤±æ›²çº¿
    if train_data:
        df_train = pd.DataFrame(train_data)
        axes[0, 0].plot(df_train['step'], df_train['loss'],
                       linewidth=2, marker='o', markersize=4, label='è®­ç»ƒæŸå¤±')
        axes[0, 0].set_xlabel('è®­ç»ƒæ­¥æ•° (Steps)', fontsize=12)
        axes[0, 0].set_ylabel('æŸå¤±å€¼ (Loss)', fontsize=12)
        axes[0, 0].set_title('è®­ç»ƒæŸå¤±æ›²çº¿', fontsize=14, fontweight='bold')
        axes[0, 0].legend(fontsize=10)
        axes[0, 0].grid(True, alpha=0.3)

    # 2. éªŒè¯æŸå¤±æ›²çº¿
    if eval_data:
        df_eval = pd.DataFrame(eval_data)
        axes[0, 1].plot(df_eval['step'], df_eval['eval_loss'],
                       linewidth=2, marker='s', markersize=4,
                       color='orange', label='éªŒè¯æŸå¤±')
        axes[0, 1].set_xlabel('è®­ç»ƒæ­¥æ•° (Steps)', fontsize=12)
        axes[0, 1].set_ylabel('æŸå¤±å€¼ (Loss)', fontsize=12)
        axes[0, 1].set_title('éªŒè¯æŸå¤±æ›²çº¿', fontsize=14, fontweight='bold')
    axes[0, 1].legend(fontsize=10)
        axes[0, 1].grid(True, alpha=0.3)

    # 3. è®­ç»ƒå’ŒéªŒè¯æŸå¤±å¯¹æ¯”
    if train_data and eval_data:
        axes[1, 0].plot(df_train['step'], df_train['loss'],
                       linewidth=2, label='è®­ç»ƒæŸå¤±', alpha=0.8)
        axes[1, 0].plot(df_eval['step'], df_eval['eval_loss'],
                       linewidth=2, label='éªŒè¯æŸå¤±', alpha=0.8)
        axes[1, 0].set_xlabel('è®­ç»ƒæ­¥æ•° (Steps)', fontsize=12)
        axes[1, 0].set_ylabel('æŸå¤±å€¼ (Loss)', fontsize=12)
        axes[1, 0].set_title('è®­ç»ƒ vs éªŒè¯æŸå¤±å¯¹æ¯”', fontsize=14, fontweight='bold')
        axes[1, 0].legend(fontsize=10)
        axes[1, 0].grid(True, alpha=0.3)

     # è®¡ç®—è¿‡æ‹ŸåˆæŒ‡æ ‡
        if len(df_eval) > 0:
            last_train_loss = df_train['loss'].iloc[-1]
            last_eval_loss = df_eval['eval_loss'].iloc[-1]
            gap = last_eval_loss - last_train_loss
            axes[1, 0].text(0.02, 0.98,
                          f'æœ€ç»ˆè®­ç»ƒæŸå¤±: {last_train_loss:.4f}\n'
                          f'æœ€ç»ˆéªŒè¯æŸå¤±: {last_eval_loss:.4f}\n'
                          f'æŸå¤±å·®è·: {gap:.4f}',
                          transform=axes[1, 0].transAxes,
                          verticalalignment='top',
                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),
                          fontsize=10)

    # 4. å­¦ä¹ ç‡å˜åŒ–ï¼ˆå¦‚æœæœ‰ï¼‰
    lr_data = [entry for entry in log_history if 'learning_rate' in entry]
    if lr_data:
        df_lr = pd.DataFrame(lr_data)
        axes[1, 1].plot(df_lr['step'], df_lr['learning_rate'],
                       linewidth=2, color='green', marker='d', markersize=4)
        axes[1, 1].set_xlabel('è®­ç»ƒæ­¥æ•° (Steps)', fontsize=12)
        axes[1, 1].set_ylabel('å­¦ä¹ ç‡ (Learning Rate)', fontsize=12)
        axes[1, 1].set_title('å­¦ä¹ ç‡å˜åŒ–æ›²çº¿', fontsize=14, fontweight='bold')
        axes[1, 1].grid(True, alpha=0.3)
        axes[1, 1].ticklabel_format(style='scientific', axis='y', scilimits=(0,0))
    else:
        axes[1, 1].text(0.5, 0.5, 'æ— å­¦ä¹ ç‡æ•°æ®',
                       ha='center', va='center', fontsize=14)
        axes[1, 1].axis('off')

    plt.tight_layout()

    # ä¿å­˜å›¾è¡¨
    output_path = Path(output_dir) / 'training_curves.png'
    plt.savefig(output_path, dpi=300, bnches='tight')
    print(f"âœ… è®­ç»ƒæ›²çº¿å·²ä¿å­˜: {output_path}")

    plt.close()

def plot_epoch_summary(state, output_dir):
    """ç»˜åˆ¶æ¯ä¸ª epoch çš„æ±‡æ€»ç»Ÿè®¡"""

    log_history = state.get('log_history', [])

    # æŒ‰ epoch åˆ†ç»„
    epoch_data = {}
    for entry in log_history:
        if 'epoch' in entry:
            epoch = entry['epoch']
            if epoch not in epoch_data:
                epoch_data[epoch] = {'train_loss': [], 'eval_loss': None}
          if 'loss' in entry:
                epoch_data[epoch]['train_loss'].append(entry['loss'])
            if 'eval_loss' in entry:
                epoch_data[epoch]['eval_loss'] = entry['eval_loss']

    if not epoch_data:
        print("âš ï¸  æ²¡æœ‰ epoch æ•°æ®")
        return

    # å‡†å¤‡æ•°æ®
    epochs = sorted(epoch_data.keys())
    avg_train_loss = [np.mean(epoch_data[e]['train_loss']) if epoch_data[e]['train_loss'] else 0
                     for e in epochs]
    eval_loss = [epoch_data[e]['eval_loss'] if epoch_data[e]['eval_loss'] else 0
                for e in epochs]

    # åˆ›å»ºå›¾è¡¨
    fig, ax = plt.subplots(figsize=(12, 6))

    x = np.arange((epochs))
    width = 0.35

    bars1 = ax.bar(x - width/2, avg_train_loss, width, label='å¹³å‡è®­ç»ƒæŸå¤±', alpha=0.8)
    bars2 = ax.bar(x + width/2, eval_loss, width, label='éªŒè¯æŸå¤±', alpha=0.8)

    ax.set_xlabel('Epoch', fontsize=12)
    ax.set_ylabel('æŸå¤±å€¼ (Loss)', fontsize=12)
    ax.set_title('æ¯ä¸ª Epoch çš„æŸå¤±å¯¹æ¯”', fontsize=14, fontweight='bold')
    ax.set_xticks(x)
    ax.set_xticklabels([f'Epoch {int(e)}' for e in epochs])
    ax.legend(fontsize=10)
    ax.grid(True, alpha=0.3, axis='y')

    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bars in [bars1, bars2]:
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{height:.4f}',
                   ha='center', va='bottom', fontsize=9)

    plt.tight_layout()

    # ä¿å­˜å›¾è¡¨
    output_path = Path(output_dir) / 'epoch_summary.png'
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"âœ… Epoch æ±‡æ€»å·²ä¿å­˜: {output_path}")

    plt.close()

def generate_training_report(state, output_dir):
    """ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š"""

    log_history = state.get('log_history', [])

    if not log_history:
        return

    # æå–å…³é”®æŒ‡æ ‡
    train_losses = [e['loss'] for e in log_history if 'loss' in e]
    eval_losses = [e['eval_loss'] for e in log_history if 'eval_loss' in e]

    report = f"""
# è®­ç»ƒæŠ¥å‘Š

## è®­ç»ƒé…ç½®
- æ€»è®­ç»ƒæ­¥æ•°: {state.get('global_step', 'N/A')}
- æ€» Epoch æ•°: {state.get('epoch', 'N/A')}
- æœ€ä½³æ¨¡å‹æ£€æŸ¥ç‚¹: {state.get('best_model_checkpoint', 'N/A')}

## è®­ç»ƒæŒ‡æ ‡

### è®­ç»ƒæŸå¤±
- åˆå§‹æŸå¤±: {train_losses[0]:.4f}
- æœ€ç»ˆæŸå¤±: {train_losses[-1]:.4f}
- æœ€ä½æŸå¤±: {min(train_losses):.4f}
- å¹³å‡æŸå¤±: {np.mean(train_losses):.4f}
- æŸå¤±ä¸‹é™: {((train_losses[0] - train_losses[-1]) / train_losses[0] * 100):.2f}%

### éªŒè¯æŸå¤±
"""

    if eval_losses:
        report += f"""- åˆå§‹éªŒè¯æŸå¤±: {eval_losses[0]:.4f}
- æœ€ç»ˆéªŒè¯æŸå¤±: {eval_losses[-1]:.4f}
- æœ€ä½éªŒè¯æŸå¤±: {min(eval_losses):.4f}
- å¹³å‡éªŒè¯æŸå¤±: {np.mean(eval_losses):.4f}

### è¿‡æ‹Ÿåˆåˆ†æ
- è®­ç»ƒ-éªŒè¯æŸå¤±å·®è·: {(eval_losses[-1] - train_losses[-1]):.4f}
- è¿‡æ‹Ÿåˆç¨‹åº¦: {'è½»å¾®' if abs(eval_losses[-1] - train_losses[-1]) < 0.1 else 'ä¸­ç­‰' if abs(eval_losses[-1] - train_losses[-1]) < 0.3 else 'ä¸¥é‡'}
"""

    report += f"""
## è®­ç»ƒç¨³å®šæ€§
- è®­ç»ƒæŸå¤±æ ‡å‡†å·®: {np.std(train_losses):.4f}
- è®­ç»ƒæŸå¤±å˜å¼‚ç³»æ•°: {(np.std(train_losses) / np.mean(train_losses)):.4f}

## å»ºè®®
"""

    # æ ¹æ®æŒ‡æ ‡ç»™å‡ºå»ºè®®
    if eval_losses and eval_losses[-1] > train_losses[-1] + 0.3:
        report += "- âš ï¸ æ£€æµ‹åˆ°æ˜æ˜¾è¿‡æ‹Ÿåˆï¼Œå»ºè®®å¢åŠ æ­£åˆ™åŒ–æˆ–å‡å°‘è®­ç»ƒè½®æ•°\n"

    if train_losses[-1] > train_losses[0] * 0.8:
        report += "- âš ï¸ æŸå¤±ä¸‹é™ä¸æ˜æ˜¾ï¼Œå»ºè®®è°ƒæ•´å­¦ä¹ ç‡æˆ–å¢åŠ è®­ç»ƒè½®æ•°\n"

    if np.std(train_losses) > np.mean(train_losses) * 0.5:
        report += "- âš ï¸ è®­ç»ƒä¸ç¨³å®šï¼Œå»ºè®®é™ä½å­¦ä¹ ç‡æˆ–è°ƒæ•´æ‰¹æ¬¡å¤§å°\n"

    if not (eval_losses and eval_losses[-1] > train_losses[-1] + 0.3) and \
       not (train_losses[-1] > train_losses[0] * 0.8):
        report += "- âœ… è®­ç»ƒæ•ˆæœè‰¯å¥½ï¼Œæ¨¡å‹æ”¶æ•›æ­£å¸¸\n"

    # ä¿å­˜æŠ¥å‘Š
    output_path = Path(output_dir) / 'training_report.md'
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(report)

    print(f"âœ… è®­ç»ƒæŠ¥å‘Šå·²ä¿å­˜: {output_path}")

def main():
    """ä¸»å‡½æ•°"""

    # è·¯å¾„é…ç½®
    base_dir = Path(__file__).parent.parent
    model_dir = base_dir / "models" / "qwen2vl_ham10000_lora"
    output_dir = base_dir / "models" / "visualizations"
    output_dir.mkdir(parents=True, exist_ok=True)

    print("ğŸ“Š å¼€å§‹ç”Ÿæˆè®­ç»ƒå¯è§†åŒ–...")

    # åŠ è½½è®­ç»ƒæ—¥å¿—
    state = load_training_logs(model_dir)

    if state is None:
        print("âŒ æ— æ³•åŠ è½½è®­ç»ƒæ—¥å¿—")
        return

    # ç”Ÿæˆå¯è§†åŒ–
    print("\nğŸ“ˆ ç»˜åˆ¶è®­ç»ƒæ›²çº¿...")
    plot_loss_curves(state, output_dir)

    print("\nğŸ“Š ç»˜åˆ¶ Epoch æ±‡æ€»...")
    plot_epoch_summary(state, output_dir)

    print("\nğŸ“ ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š...")
    generate_training_report(state, output_dir)

    print(f"\nâœ… æ‰€æœ‰å¯è§†åŒ–å·²å®Œæˆï¼")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")

if __name__ == "__main__":
    main()
